#!/bin/bash

# Copyright (C) 2012 The Regents of The University California.
# All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

get_abs_path() {
    local PARENT_DIR=$(dirname "$1")
    cd "$PARENT_DIR"
    local ABS_PATH="$(pwd)"/"$(basename $1)"
    cd - >/dev/null
    echo $ABS_PATH
}

CURRENTFILE=`get_abs_path $0`
BINDIR="`dirname $CURRENTFILE`"
FWDIR="`dirname $BINDIR`/.."

# Load environment variables from conf/shark-env.sh, if it exists
if [ -e $FWDIR/conf/shark-env.sh ] ; then
  . $FWDIR/conf/shark-env.sh
fi

# Hive related section.
if [ -z $HIVE_DEV_HOME ] ; then
  echo "No HIVE_DEV_HOME specified. Please set HIVE_DEV_HOME"
  exit 1
fi

# Hive related section.
if [ -z $HADOOP_HOME ] ; then
  echo "No HADOOP_HOME specified. Please set HADOOP_HOME"
  exit 1
fi

if [ -n "$TEST_FILE" ] ; then
  TEST_FILE=`get_abs_path $TEST_FILE`
  export TEST_FILE
fi

# Detect hadoop version if not defined
if [ "x$HADOOP_VERSION" == "x" ]; then
    HADOOP_VERSION=$($HADOOP_HOME/bin/hadoop version | awk '{if (NR == 1) {print $2;}}');
fi

hadoop_version_re="^([[:digit:]]+)\.([[:digit:]]+)(\.([[:digit:]]+))?.*$"

if [[ "$HADOOP_VERSION" =~ $hadoop_version_re ]]; then
    hadoop_major_ver=${BASH_REMATCH[1]}
    hadoop_minor_ver=${BASH_REMATCH[2]}
    hadoop_patch_ver=${BASH_REMATCH[4]}
else
    echo "Unable to determine Hadoop version information."
    echo "'hadoop version' returned:"
    echo `$HADOOP version`
    exit 1
fi

SPARK_CLASSPATH+=":${HIVE_DEV_HOME}/build/ql/test/classes"
SPARK_CLASSPATH+=":${HIVE_DEV_HOME}/data/conf"
export SPARK_CLASSPATH

BUILD_PATH=$HIVE_DEV_HOME/build/ql

# Set variables used by unit tests (ex. create_like.q).
TEST_JAVA_OPTS="-Dbuild.dir=${HIVE_DEV_HOME}/build/ql "
TEST_JAVA_OPTS+="-Dbuild.dir.hive=${HIVE_DEV_HOME}/build "
TEST_JAVA_OPTS+="-Dbuild.ivy.lib.dir=${HIVE_DEV_HOME}/build/ivy/lib "
TEST_JAVA_OPTS+="-Dderby.version=10.4.2.0 "
TEST_JAVA_OPTS+="-Dlog4j.configuration=file://${HIVE_DEV_HOME}/data/conf/hive-log4j.properties "
TEST_JAVA_OPTS+="-Dtest.log.dir=${BUILD_PATH}/test/logs "
TEST_JAVA_OPTS+="-Dtest.output.overwrite=false "
TEST_JAVA_OPTS+="-Dtest.src.data.dir=${HIVE_DEV_HOME}/data "
TEST_JAVA_OPTS+="-Dtest.tmp.dir=${BUILD_PATH}/tmp "
TEST_JAVA_OPTS+="-Dtest.warehouse.dir=pfile://${BUILD_PATH}/test/data/warehouse "

if [[ $hadoop_major_ver -eq 2 && $hadoop_minor_ver -ge 3 ]]; then
	TEST_JAVA_OPTS+="-Dtest.dfs.mkdir=\"-mkdir -p\" "
else
	TEST_JAVA_OPTS+="-Dtest.dfs.mkdir=-mkdir "
fi

#TEST_JAVA_OPTS+="-Duser.dir=${HIVE_DEV_HOME}/ql "

export TEST_JAVA_OPTS

# Set the current directory to hive/ql since lots of tests use relative path.
cd ${HIVE_DEV_HOME}/ql

if [ "$TEST_WITH_ANT" == "1" ] ; then
  export CLASSPATH
  export RUNNER="ant -noclasspath -nouserlib -f $FWDIR/bin/dev/build_test.xml test"
  exec $FWDIR/run "$@"
else
  export SHARK_LAUNCH_WITH_JAVA=1
  exec $FWDIR/run junit.textui.TestRunner shark.TestSharkCliDriver "$@"
fi
